{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama_index==0.11.4\n",
    "# !pip install PyYAML\n",
    "# !pip install docx2txt==0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"sk-your-api-key\"\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mèo Ú của bạn đang ngủ bên cửa sổ.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "text = \"Tôi có một bé mèo, cậu ấy tên là Mèo Ú. Cậu ấy đang ngủ bên cửa sổ. Tôi rất quý cậu ấy.\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])\n",
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"Tôi là Tiềm, mèo Ú của tôi đang làm gì nhỉ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi là Tiềm, mèo Ú của tôi đang làm gì nhỉ?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_ELGpkWmYBxR8LQyqyajSJK9B', function=Function(arguments='{\"input\":\"Mèo Ú của Tiềm đang làm gì?\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú đang ngủ bên cửa sổ.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_ELGpkWmYBxR8LQyqyajSJK9B'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo Ú của bạn đang ngủ bên cửa sổ.', additional_kwargs={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn tên là Tiềm.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"Tôi tên là gì?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi là Tiềm, mèo Ú của tôi đang làm gì nhỉ?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_yQOxBuLn9WWLzsuad3Vtz4rM', function=Function(arguments='{\"input\":\"Mèo Ú đang làm gì?\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú đang ngủ bên cửa sổ.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_yQOxBuLn9WWLzsuad3Vtz4rM'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo Ú của bạn đang ngủ bên cửa sổ.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi tên là gì?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Bạn tên là Tiềm.', additional_kwargs={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamchat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có vẻ như bạn đang muốn biết về tình cảm của mình đối với Mèo Ú. Dưới đây là một bài thơ thể hiện tình yêu dành cho Mèo Ú:\n",
      "\n",
      "Mèo Ú nhỏ bé, đáng yêu vô cùng,  \n",
      "Trong lòng tôi, cậu là ánh trăng rằm.  \n",
      "Mỗi buổi sáng, cậu nhảy nhót vui,  \n",
      "Mang đến nụ cười, xua tan u ám.\n",
      "\n",
      "Lông mềm mại, như mây trời bay,  \n",
      "Ánh mắt trong veo, như nước hồ đầy.  \n",
      "Cậu là bạn thân, là niềm an ủi,  \n",
      "Mỗi phút giây bên nhau, thật tuyệt vời.\n",
      "\n",
      "Khi cậu ngủ say, tôi ngắm nhìn,  \n",
      "Tình yêu dành cho cậu, mãi không phai.  \n",
      "Mèo Ú ơi, cậu là món quà,  \n",
      "Trong trái tim tôi, cậu luôn là nhất."
     ]
    }
   ],
   "source": [
    "response = chat_engine.stream_chat(\"Tôi có yêu cậu ấy không? Viết một bài thơ về Mèo Ú đi.\")\n",
    "for token in response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi là Tiềm, mèo Ú của tôi đang làm gì nhỉ?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_SztjRMkbEtABahzyhVb5CSGU', function=Function(arguments='{\"input\":\"Mèo Ú của Tiềm đang làm gì?\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú đang ngủ bên cửa sổ.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_SztjRMkbEtABahzyhVb5CSGU'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo Ú của bạn đang ngủ bên cửa sổ.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi tên là gì?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Bạn tên là Tiềm.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi có yêu cậu ấy không? Viết một bài thơ về Mèo Ú đi.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='', additional_kwargs={'tool_calls': [ChoiceDeltaToolCall(index=0, id='call_DLFF5GI6IKdnXFn8bPejDkmT', function=ChoiceDeltaToolCallFunction(arguments='{\"input\":\"Viết một bài thơ về Mèo Ú\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú nằm bên cửa sổ,  \\nGiấc mơ bay bổng, nhẹ nhàng trôi.  \\nLông mềm mại, ánh nắng rực rỡ,  \\nCậu ấy là niềm vui trong đời.  \\n\\nMắt nhắm nghiền, mơ về cánh đồng,  \\nChạy nhảy vui đùa, không lo âu sầu.  \\nTôi yêu cậu, tình thương vô bờ,  \\nMèo Ú ơi, mãi mãi bên nhau.  \\n\\nKhi thức dậy, cậu sẽ nghịch ngợm,  \\nChạy quanh nhà, đuổi theo bóng mờ.  \\nMỗi ngày trôi, thêm nhiều kỷ niệm,  \\nMèo Ú ơi, cậu là món quà.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_DLFF5GI6IKdnXFn8bPejDkmT'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Dưới đây là bài thơ về Mèo Ú:\\n\\nMèo Ú nằm bên cửa sổ,  \\nGiấc mơ bay bổng, nhẹ nhàng trôi.  \\nLông mềm mại, ánh nắng rực rỡ,  \\nCậu ấy là niềm vui trong đời.  \\n\\nMắt nhắm nghiền, mơ về cánh đồng,  \\nChạy nhảy vui đùa, không lo âu sầu.  \\nTôi yêu cậu, tình thương vô bờ,  \\nMèo Ú ơi, mãi mãi bên nhau.  \\n\\nKhi thức dậy, cậu sẽ nghịch ngợm,  \\nChạy quanh nhà, đuổi theo bóng mờ.  \\nMỗi ngày trôi, thêm nhiều kỷ niệm,  \\nMèo Ú ơi, cậu là món quà.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi có yêu cậu ấy không? Viết một bài thơ về Mèo Ú đi.', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Có vẻ như bạn đang muốn biết về tình cảm của mình đối với Mèo Ú. Dưới đây là một bài thơ thể hiện tình yêu dành cho Mèo Ú:\\n\\nMèo Ú nhỏ bé, đáng yêu vô cùng,  \\nTrong lòng tôi, cậu là ánh trăng rằm.  \\nMỗi buổi sáng, cậu nhảy nhót vui,  \\nMang đến nụ cười, xua tan u ám.\\n\\nLông mềm mại, như mây trời bay,  \\nÁnh mắt trong veo, như nước hồ đầy.  \\nCậu là bạn thân, là niềm an ủi,  \\nMỗi phút giây bên nhau, thật tuyệt vời.\\n\\nKhi cậu ngủ say, tôi ngắm nhìn,  \\nTình yêu dành cho cậu, mãi không phai.  \\nMèo Ú ơi, cậu là món quà,  \\nTrong trái tim tôi, cậu luôn là nhất.', additional_kwargs={})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat_repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Chào bạn! Bạn cần giúp gì hôm nay?\n",
      "\n",
      "Assistant: Mèo ú thường được biết đến với vẻ ngoài dễ thương và tính cách thân thiện. Bạn có kỷ niệm nào đặc biệt với mèo ú không? Hoặc bạn muốn biết thêm thông tin gì về chúng?\n",
      "\n",
      "Assistant: Mèo ú đang ngủ bên cửa sổ. Có vẻ như cậu ấy đang tận hưởng một giấc ngủ ngon! Bạn có muốn biết thêm điều gì về mèo ú không?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Chào bạn', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Chào bạn! Bạn cần giúp gì hôm nay?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi nhớ mèo ú', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo ú thường được biết đến với vẻ ngoài dễ thương và tính cách thân thiện. Bạn có kỷ niệm nào đặc biệt với mèo ú không? Hoặc bạn muốn biết thêm thông tin gì về chúng?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Cậu ấy đang làm gì?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_tOzuSka3vdbSgGdB9VSuQ6sz', function=Function(arguments='{\"input\":\"Mèo ú đang làm gì?\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú đang ngủ bên cửa sổ.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_tOzuSka3vdbSgGdB9VSuQ6sz'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo ú đang ngủ bên cửa sổ. Có vẻ như cậu ấy đang tận hưởng một giấc ngủ ngon! Bạn có muốn biết thêm điều gì về mèo ú không?', additional_kwargs={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Có, bạn rất quý mèo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Tôi có yêu mèo không?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_6sIbQjbsc9POkGhR6hdniFXU', function=Function(arguments='{\"input\":\"Tôi có yêu mèo không?\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Có, bạn rất quý mèo.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_6sIbQjbsc9POkGhR6hdniFXU'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Có, bạn rất quý mèo.', additional_kwargs={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xóa lịch sử chat\n",
    "chat_engine.reset()\n",
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cơ chế quản lí lịch sử chat\n",
    "\n",
    "## ChatMemoryBuffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "text = \"Mèo Ú đi lạc, mấy ngày rồi cậu ấy không về nhà, tôi lo quá!\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chat_store = SimpleChatStore.from_persist_path(\n",
    "        persist_path = \"chat_memory.json\"\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    chat_store = SimpleChatStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit= 20,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"User 1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_engine = index.as_chat_engine(memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Xin chào! Bạn cần giúp gì hôm nay?\n",
      "Bot: Mèo Ú đang đi lạc và đã không về nhà mấy ngày rồi.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    response = chat_engine.chat(user_input)\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatMessage(role=<MessageRole.USER: 'user'>, content='Xin chào', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Xin chào! Bạn cần giúp gì hôm nay?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.USER: 'user'>, content='Mèo Ú đang ở đâu?', additional_kwargs={}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_w1KN9B8ZsN8ZItPpWk4uBj9v', function=Function(arguments='{\"input\":\"Mèo Ú đang ở đâu?\"}', name='query_engine_tool'), type='function')]}),\n",
       " ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú đi lạc và đã không về nhà mấy ngày rồi.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_w1KN9B8ZsN8ZItPpWk4uBj9v'}),\n",
       " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo Ú đang đi lạc và đã không về nhà mấy ngày rồi.', additional_kwargs={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_engine.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleChatStore(store={'User 1': [ChatMessage(role=<MessageRole.USER: 'user'>, content='Xin chào', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Xin chào! Bạn cần giúp gì hôm nay?', additional_kwargs={}), ChatMessage(role=<MessageRole.USER: 'user'>, content='Mèo Ú đang ở đâu?', additional_kwargs={}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=None, additional_kwargs={'tool_calls': [ChatCompletionMessageToolCall(id='call_w1KN9B8ZsN8ZItPpWk4uBj9v', function=Function(arguments='{\"input\":\"Mèo Ú đang ở đâu?\"}', name='query_engine_tool'), type='function')]}), ChatMessage(role=<MessageRole.TOOL: 'tool'>, content='Mèo Ú đi lạc và đã không về nhà mấy ngày rồi.', additional_kwargs={'name': 'query_engine_tool', 'tool_call_id': 'call_w1KN9B8ZsN8ZItPpWk4uBj9v'}), ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='Mèo Ú đang đi lạc và đã không về nhà mấy ngày rồi.', additional_kwargs={})]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store.persist(persist_path=\"chat_memory.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các chế độ trò chuyện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chế độ đơn giản "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Xin chào, Tiềm! Rất vui được gặp bạn. Bạn có điều gì muốn chia sẻ hoặc hỏi không?\n",
      "\n",
      "Assistant: Nghe thật tuyệt! Kem mát lạnh là món ăn giải khát tuyệt vời, đặc biệt trong những ngày nóng. Bạn thích loại kem nào nhất? Kem trái cây, kem sô cô la hay kem vani?\n",
      "\n",
      "Assistant: Có, bạn đã giới thiệu tên là Tiềm. Nếu bạn muốn chia sẻ thêm về bản thân hoặc có câu hỏi nào khác, hãy cho tôi biết nhé!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "chat_engine = SimpleChatEngine.from_defaults()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chế độ ngữ cảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "text = \"Đêm qua đi chơi về muộn, mèo Ú bị sập bẫy!\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Xin chào! Bạn cần giúp gì hôm nay? Có phải bạn muốn tìm hiểu thêm về vụ việc mèo Ú bị bắt không?\n",
      "\n",
      "Assistant: Tốt! Để tìm ra ai đã bắt mèo Ú, chúng ta cần thu thập một số thông tin và đặt ra một số câu hỏi. Dưới đây là một số bước mà chúng ta có thể thực hiện:\n",
      "\n",
      "1. **Thời gian và địa điểm**: Bạn có biết chính xác thời gian và địa điểm mà mèo Ú bị bắt không? Điều này có thể giúp xác định ai có mặt ở đó vào thời điểm đó.\n",
      "\n",
      "2. **Những người xung quanh**: Có ai đã thấy mèo Ú hoặc có ai đã ở gần khu vực đó vào thời điểm mèo Ú bị bắt không? Họ có thể cung cấp thông tin quan trọng.\n",
      "\n",
      "3. **Bẫy**: Bạn có biết loại bẫy nào đã được sử dụng để bắt mèo Ú không? Điều này có thể giúp xác định ai có thể đã đặt bẫy.\n",
      "\n",
      "4. **Động cơ**: Có ai trong khu vực có động cơ để bắt mèo Ú không? Có thể là một người hàng xóm, một người yêu động vật, hoặc ai đó có mâu thuẫn với bạn.\n",
      "\n",
      "5. **Dấu vết**: Có dấu vết nào xung quanh khu vực mà mèo Ú bị bắt không? Ví dụ như dấu chân, đồ vật lạ, hoặc bất kỳ điều gì có thể giúp xác định thủ phạm.\n",
      "\n",
      "Nếu bạn có thêm thông tin nào, hãy chia sẻ để chúng ta có thể cùng nhau tìm ra ai đã bắt mèo Ú!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode= \"context\",\n",
    "    system_prompt=(\"Bạn là một nhà thám tử, \"\n",
    "                   \"hãy giúp tôi tìm ra ai đã bắt mèo Ú!\")\n",
    ")\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CondenseQuestionChatEngine - Chế độ câu hỏi cô đọng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Xin chào! Bạn có muốn chia sẻ thêm về Mèo Ú không?\n",
      "\n",
      "Assistant: Mèo Ú của bạn đang ngủ bên cửa sổ.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode= \"condense_question\"\n",
    ")\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condense Plus Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "\n",
    "text = \"Đêm qua đi chơi về muộn, mèo Ú bị sập bẫy!\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Entering Chat REPL =====\n",
      "Type \"exit\" to exit.\n",
      "\n",
      "Assistant: Xin chào! Bạn có khỏe không? Nếu bạn muốn chia sẻ điều gì về mèo của bạn hoặc bất kỳ điều gì khác, mình rất sẵn lòng lắng nghe! Mèo Ú của bạn đang làm gì?\n",
      "\n",
      "Assistant: Mèo thường không kêu \"gâu gâu\" như chó, mà chúng thường phát ra âm thanh như \"meo meo\". Có thể bạn đang nhầm lẫn giữa tiếng kêu của mèo và chó. Mèo Ú của bạn có thể có những âm thanh đặc trưng riêng, nhưng chắc chắn là không phải \"gâu gâu\". Nếu bạn có bất kỳ câu hỏi nào khác về mèo, mình rất vui lòng giúp đỡ!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_engine = index.as_chat_engine(\n",
    "    chat_mode= \"condense_plus_context\"\n",
    ")\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xin lỗi, nhưng tôi không thể kiểm tra thời gian hiện tại. Bạn có thể xem đồng hồ hoặc thiết bị của mình để biết giờ nhé!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.chat_engine import SimpleChatEngine\n",
    "\n",
    "chat_engine = SimpleChatEngine.from_defaults()\n",
    "respone = chat_engine.chat(\"Em ơi mấy giờ rồi?\")\n",
    "print(respone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_date_time()->str:\n",
    "    \"\"\"Get current date and time\n",
    "\n",
    "    Returns:\n",
    "        str: Current date and time\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "get_date_time_tool = FunctionTool.from_defaults(fn=get_date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    tools = [get_date_time_tool],\n",
    ")\n",
    "response = agent.chat(\"Em ơi mấy giờ rồi?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bây giờ là 22 giờ 32 phút.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Engine Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bây giờ là 23 giờ 08 phút.\n",
      "Mèo Ú của anh đã bị sập bẫy khi đi chơi về muộn. Anh có thể tìm kiếm xung quanh khu vực đó để xem có thể tìm thấy mèo Ú không.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "\n",
    "text = \"Đêm qua đi chơi về muộn, mèo Ú bị sập bẫy!\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "query_tool = QueryEngineTool.from_defaults(query_engine=query_engine, \n",
    "                                           description=\"Công cụ tìm kiếm thông tin về mèo Ú\")\n",
    "agent = OpenAIAgent.from_tools(tools=[query_tool, get_date_time_tool])\n",
    "\n",
    "respone_1 = agent.chat(\"Em ơi mấy giờ rồi?\")\n",
    "respone_2 = agent.chat(\"Em có biết mèo Ú của anh ở đâu không?\")\n",
    "\n",
    "print(respone_1)\n",
    "print(respone_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiện tại là 23:42:51. \n",
      "\n",
      "Mèo Ú là một con mèo đã bị sập bẫy khi đi chơi về muộn.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "\n",
    "text = \"Đêm qua đi chơi về muộn, mèo Ú bị sập bẫy!\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "query_tool = QueryEngineTool.from_defaults(query_engine=query_engine, \n",
    "                                           description=\"Công cụ tìm kiếm thông tin về mèo Ú\")\n",
    "agent = OpenAIAgent.from_tools(tools=[query_tool, get_date_time_tool])\n",
    "\n",
    "respone_1 = agent.chat(\"Em ơi mấy giờ rồi? Mèo ú của anh đâu?\")\n",
    "\n",
    "print(respone_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open AI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Thu ơi, hãy nhân 5 với 3 giúp tớ nhé. Mà cậu biết mèo Ú của tớ đã thế nào không?\n",
      "=== Calling Function ===\n",
      "Calling function: multiply with args: {\"a\": 5, \"b\": 3}\n",
      "Got output: 15\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: query_engine_tool with args: {\"input\": \"mèo Ú\"}\n",
      "Got output: Mèo Ú là một con mèo đã trở về vào sáng ngày 4 tháng 9 năm 2024, dưới cơn mưa tầm tã.\n",
      "========================\n",
      "\n",
      "Kết quả của phép nhân 5 với 3 là 15. \n",
      "\n",
      "Còn về mèo Ú của cậu, nó đã trở về vào sáng ngày 4 tháng 9 năm 2024, dưới cơn mưa tầm tã. Hy vọng mèo Ú của cậu đã an toàn và khỏe mạnh!\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Trả về kết quả phép nhân a với b\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def save_result(result: int) -> str:\n",
    "    \"\"\"Lưu kết quả vào file result.txt\"\"\"\n",
    "    with open(\"result.txt\", \"w\") as f:\n",
    "        f.write(str(result))\n",
    "    return \"Result saved!\"\n",
    "\n",
    "text = \"Sáng ngày 4 tháng 9 năm 2024, mèo Ú trở về dưới cơn mưa tầm tã.\"\n",
    "doc = Document(text=text)\n",
    "index = VectorStoreIndex.from_documents([doc])\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "query_tool = QueryEngineTool.from_defaults(query_engine=query_engine, \n",
    "                                           description=\"Công cụ tìm kiếm thông tin về mèo Ú\")\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "save_result_tool = FunctionTool.from_defaults(fn=save_result)\n",
    "\n",
    "openai_agent = OpenAIAgent.from_tools(\n",
    "    tools=[query_tool, multiply_tool, save_result_tool],\n",
    "    system_prompt=\"Bạn là Thu, người bạn tri kỷ, hiểu chuyện và thành thật của tôi.\",\n",
    "    verbose=True\n",
    ")\n",
    "response = openai_agent.chat(\"Thu ơi, hãy nhân 5 với 3 giúp tớ nhé. Mà cậu biết mèo Ú của tớ đã thế nào không?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 47f4f1b4-0297-41a9-9154-3346569e5d9a. Step input: Thu ơi, hãy nhân 5 với 3 giúp tớ nhé. Mà cậu biết mèo Ú của tớ đã thế nào không?\n",
      "\u001b[1;3;38;5;200mThought: Người dùng đang yêu cầu tôi thực hiện phép nhân 5 với 3 và cũng hỏi về mèo Ú của họ. Tôi sẽ bắt đầu bằng cách thực hiện phép nhân trước.\n",
      "Action: multiply\n",
      "Action Input: {'a': 5, 'b': 3}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 15\n",
      "\u001b[0m> Running step 4b73701e-9f2c-4b91-93fc-cbf34466808e. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: Tôi đã thực hiện phép nhân và kết quả là 15. Bây giờ tôi sẽ tìm kiếm thông tin về mèo Ú của người dùng.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'mèo Ú'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Mèo Ú là một con mèo đã trở về vào sáng ngày 4 tháng 9 năm 2024, dưới cơn mưa tầm tã.\n",
      "\u001b[0m> Running step ef519902-035a-4260-98d0-96bf691aa077. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: Tôi đã có thông tin về mèo Ú của người dùng. Bây giờ tôi có thể trả lời cả hai yêu cầu.\n",
      "Answer: Kết quả phép nhân 5 với 3 là 15. Mèo Ú của bạn đã trở về vào sáng ngày 4 tháng 9 năm 2024, dưới cơn mưa tầm tã.\n",
      "\u001b[0mKết quả phép nhân 5 với 3 là 15. Mèo Ú của bạn đã trở về vào sáng ngày 4 tháng 9 năm 2024, dưới cơn mưa tầm tã.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.agent.react import ReActAgent\n",
    "\n",
    "react_agent = ReActAgent.from_tools(\n",
    "    tools=[query_tool, multiply_tool, save_result_tool],\n",
    "    system_prompt=\"Bạn là Thu, người bạn tri kỷ, hiểu chuyện và thành thật của tôi.\",\n",
    "    verbose=True\n",
    ")\n",
    "response = react_agent.chat(\"Thu ơi, hãy nhân 5 với 3 giúp tớ nhé. Mà cậu biết mèo Ú của tớ đã thế nào không?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pits_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
